{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import tweepy \n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "################################\n",
    "#if you don't have nltk please run command below\n",
    "# nltk.download('punkt')   \n",
    "# nltk.download('stopwords')\n",
    "################################\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(self):\n",
    "# Replace the xxxxx with your twitter api keys\n",
    "    consumer_key= 'mhEpB8cHJhe5xt05df3LHEyeZ'\n",
    "    consumer_secret= 'dKImFjd55FWX4LX3R1V2VFi292DpQLj5NRXgFklbesOJp2hb82'\n",
    "    access_token= '912351283553513473-obrowBlTt2kNldW9wTPgRKonoXdYBIK'\n",
    "    access_token_secret= 'NnkI5fsyxxHVogATTUNp1oJxOfAspZrDBiNrFetR4Vakt'\n",
    "\n",
    "    hashtag_phrase = '#XERXIA'\n",
    "    try:\n",
    "        auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        api = tweepy.API(auth)\n",
    "        return api\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        exit(1)\n",
    "\n",
    "def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):\n",
    "    #create authentication for accessing Twitter\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    #initialize Tweepy API\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    tweets = api.search_tweets(\n",
    "        q=f\"{hashtag_phrase} -filter:retweets\", \n",
    "        lang=\"en\",\n",
    "        count=100)\n",
    "\n",
    "    tweets_set = set()\n",
    "    for tweet in tweets:\n",
    "        tweets_set.add(tweet)\n",
    "    tweets = list(tweets_set)\n",
    "\n",
    "    users_locs = [[\n",
    "        hashtag_phrase,\n",
    "        tweet.user.screen_name,\n",
    "        # tweet.user.location if tweet.user.location != '' else 'unknown',\n",
    "        tweet.created_at.replace(tzinfo=None),\n",
    "        remove_url(tweet.text),\n",
    "        sentiment(TextBlob(stem(cleanText(tweet.text)))),\n",
    "        tweet.user.followers_count,\n",
    "        f\"https://twitter.com/twitter/statuses/{tweet.id}\"] for tweet in tweets]\n",
    "                \n",
    "    tweet_text = pd.DataFrame(data=users_locs, \n",
    "        columns=['Hashtag','Username','Date','Tweet','Sentiment','Followers_count','tweet link'])\n",
    "    fname = hashtag_phrase\n",
    "    tweet_text.to_csv(f\"{fname}.csv\")\n",
    "\n",
    "def cleanText(text):\n",
    "    text =text.lower()\n",
    "    text =re.sub(r'@[A-Za-z0-9]+','',text) #remove @mentions\n",
    "    text =re.sub(r'#','',text) #remove the '#' symbol\n",
    "    text =re.sub(r'RT[\\s]+','',text)    #Remove RT\n",
    "    text =re.sub(r'https?:\\/\\/\\S+','',text) #Remove the hyper link\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) #set to chr\n",
    "\n",
    "    return text\n",
    "\n",
    "def sentiment(cleaned_text):\n",
    "    # Returns the sentiment based on the polarity of the input TextBlob object\n",
    "    if cleaned_text.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif cleaned_text.sentiment.polarity < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "def stem(text):\n",
    "    # This function is used to stem the given sentence\n",
    "    porter = PorterStemmer()\n",
    "    token_words = word_tokenize(text)\n",
    "    stem_sentence = []\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "    return \" \".join(stem_sentence)\n",
    "\n",
    "def remove_url(txt):\n",
    "    \"\"\"Replace URLs found in a text string with nothing \n",
    "    (i.e. it will remove the URL from the string).\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt : string\n",
    "        A text string that you want to parse and remove urls.\n",
    "    Returns\n",
    "    -------\n",
    "    The same txt string with url's removed.\n",
    "    \"\"\"\n",
    "\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "\n",
    "def remove_url_th(txt):\n",
    "    \"\"\"Replace URLs found in a text string with nothing \n",
    "    (i.e. it will remove the URL from the string).\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt : string\n",
    "        A text string that you want to parse and remove urls.\n",
    "    Returns\n",
    "    -------\n",
    "    The same txt string with url's removed.\n",
    "    \"\"\"\n",
    "\n",
    "    return \" \".join(re.sub(\"([^\\u0E00-\\u0E7Fa-zA-Z' ]|^'|'$|''|(\\w+:\\/\\/\\S+))\", \"\", txt).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'mhEpB8cHJhe5xt05df3LHEyeZ'\n",
    "consumer_secret= 'dKImFjd55FWX4LX3R1V2VFi292DpQLj5NRXgFklbesOJp2hb82'\n",
    "access_token= '912351283553513473-obrowBlTt2kNldW9wTPgRKonoXdYBIK'\n",
    "access_token_secret= 'NnkI5fsyxxHVogATTUNp1oJxOfAspZrDBiNrFetR4Vakt'\n",
    "    \n",
    "hashtag_phrase = '#XERXIA'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df642eef7b43fe7a4a517bca7a97690968a466268416ac555ac71584a4a4c66c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
